!SLIDE center subsection

# Data Ingestion: Text as Sequence of Characters



Text can be treated as sequence of characters; neural networks can be trained to answer the question "Given input character X predict the next character"; then repeat.

~~~SECTION:notes~~~

## Steal Andrey Karpathy blog pic


~~~ENDSECTION~~~

!SLIDE

# Character vs Word as Unit of Analysis 

* How many words are there? 
* How many characters are there? 
* Text->word processing is hard
  * prefix, suffix, etc
  * "old school" , "New York"
  
!SLIDE

# Sequence of Characters as SubTree in Tree of All Character Strings

Graph of 
test branch teste, testi, branch tested, branch testing

In an Recurrent Neural Network(Graves LSTM) each node is a hidden state vector


!SLIDE

# Using Recurrent Neural Networks to Write Weather Forecast

After the content that describes LSTM RNN in detail we will have a lab that builds a neural network to generate characters one character at a time from a learned corpus. 

In the lab we will train the network weather forecasts. 

***Instructor note, foreshadow the lab , do not start the lab yet, next chapter ***

!SLIDE

